{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.15 Geocoding and Mapping\n",
    "* Collect streaming tweets, then plot their locations on an interactive map\n",
    "* **Twitter disables precise location info (latitude/longitude) by default** (users must opt in to allowing Twitter to track locations) \n",
    "* Large percentage include the user’s home location information\n",
    "    * Sometimes invalid or fictitious \n",
    "* Map markers will show `location` from each tweet’s `User` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**geopy** library](https://github.com/geopy/geopy)\n",
    "* **Geocoding**&mdash;translate locations into **latitude** and **longitude**\n",
    "* **geopy** supports dozens of **geocoding web services**, many with **free or lite tiers**\n",
    "* We’ll use **OpenMapQuest geocoding service** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMapQuest Geocoding API\n",
    "* Convert locations, such as **Boston, MA** into their **latitudes** and **longitudes**, such as **42.3602534** and **-71.0582912**, for plotting on maps\n",
    "* Currently allows **15,000 transactions per month** on their free tier\n",
    "* [Sign up](https://developer.mapquest.com/)\n",
    "* Once logged in, go to \n",
    "> https://developer.mapquest.com/user/me/apps \n",
    "    * Click **Create a New Key**\n",
    "    * Fill in the `App Name` field with a name of your choosing\n",
    "    * Leave the `Callback URL` empty\n",
    "    * Click `Create App` to create an API key \n",
    "* Click your app’s name in the web page to see your **consumer key**\n",
    "* In `keys.py`, replace **YourKeyHere** in `mapquest_key` line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**folium library**](https://github.com/python-visualization/folium) and Leaflet.js JavaScript Mapping Library\n",
    "* For the maps\n",
    "* Uses **Leaflet.js JavaScript mapping library** to display maps in a web page \n",
    "* Folium save as HTML files that you can view in your web browser\n",
    "* Install folium\n",
    ">```python\n",
    "pip install folium\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps from OpenStreetMap.org\n",
    "By default, **Leaflet.js** uses **open source maps** from **`OpenStreetMap.org`**\n",
    "* To use these maps, **they require the following copyright notice**:\n",
    "> `Map data © OpenStreetMap contributors`\n",
    "and they state:\n",
    "> _You must make it clear that the data is available under the Open Database License. This can be achieved by providing a “License” or “Terms” link which links to `www.openstreetmap.org/copyright` or `www.opendatacommons.org/licenses/odbl`._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.1 Getting and Mapping the Tweets\n",
    "* We’ll use utility functions from our **`tweetutilities.py`** file and class **`LocationListener`** in **`locationlistener.py`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the API Object\n",
    "* In this case, we do this via the `get_API` utility function in `tweetutilities.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import get_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = get_API()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections Required By `LocationListener`\n",
    "* Requires two collections\n",
    "    * A **list (`tweets`)** to store the tweets we collect \n",
    "    * A **dictionary (`counts`)** to track the total number of tweets we collect and the number that have location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {'total_tweets': 0, 'locations': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LocationListener "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locationlistener import LocationListener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener = LocationListener(api, counts_dict=counts, \n",
    "    tweets_list=tweets, topic='football', limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`LocationListener`** uses our **utility function `get_tweet_content`** to extract the screen name, tweet text and location from each tweet, place that data in a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start the `Stream` of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = tweepy.Stream(auth=api.auth, listener=location_listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.filter(track=['football'], languages=['en'], is_async=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Location Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['total_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{counts[\"locations\"] / counts[\"total_tweets\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding the Locations \n",
    "* Uses our `get_geocodes` utility function \n",
    "* **OpenMapQuest geocoding service** times out when it cannot handle your request immediately\n",
    "* If so, **`get_geocodes`** notifies you, waits, then retries the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import get_geocodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_locations = get_geocodes(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Bad Location Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{bad_locations / counts[\"locations\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data \n",
    "* Use a pandas `DataFrame` to clean the data\n",
    "* `DataFrame` will contain **`NaN`** for the **`latitude`** and **`longitude`** of any tweet that did not have a valid location\n",
    "* Remove any such via `DataFrame`’s **`dropna` method** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Map with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap = folium.Map(location=[39.8283, -98.5795],  # center of U.S.\n",
    "                   tiles='Stamen Terrain',\n",
    "                   zoom_start=4, detect_retina=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`location`** &mdash; sequence containing latitude and longitude of map center point\n",
    "    * [Geographic center of the continental United States](http://bit.ly/CenterOfTheUS) \n",
    "* **`zoom_start`** &mdash; map’s initial zoom level\n",
    "* **`detect_retina`** &mdash; enables folium to use higher-resolution maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Folium `Popup` Objects for the Tweet Locations\n",
    "* **`itertuples** creates tuples from each row of the **`DataFrame`**\n",
    "* Each **tuple** contains a **property** for each **`DataFrame` column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df.itertuples():\n",
    "    text = ': '.join([t.screen_name, t.text])\n",
    "    popup = folium.Popup(text, parse_html=True)\n",
    "    marker = folium.Marker((t.latitude, t.longitude), \n",
    "                           popup=popup)\n",
    "    marker.add_to(usmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Map with Map’s **`save`** Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap.save('tweet_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Map in Jupyter \n",
    "* Evaluating the `usmap` object in Jupyter displays the interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.2 Utility Functions in `tweetutilities.py` \n",
    "### `get_tweet_content` Utility Function \n",
    "* Receives a **`Status` object (tweet)** and creates a **dictionary** containing the **tweet’s `screen_name`, `text` and `location`**\n",
    "* For the tweet’s text, we try to use the `full_text` property of an `extended_tweet` \n",
    "\n",
    "```python\n",
    "def get_tweet_content(tweet, location=False):\n",
    "    \"\"\"Return dictionary with data from tweet (a Status object).\"\"\"\n",
    "    fields = {}\n",
    "    fields['screen_name'] = tweet.user.screen_name\n",
    "\n",
    "    # get the tweet's text\n",
    "    try:  \n",
    "        fields['text'] = tweet.extended_tweet.full_text\n",
    "    except: \n",
    "        fields['text'] = tweet.text\n",
    "\n",
    "    if location:\n",
    "        fields['location'] = tweet.user.location\n",
    "\n",
    "    return fields\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function \n",
    "* Receives a list of dictionaries containing tweets and **geocodes their locations**\n",
    "* If geocoding is successful for a tweet, adds the **latitude** and **longitude** to the tweet’s **dictionary in `tweet_list`**\n",
    "* Requires class **`OpenMapQuest`** from the **geopy module**\n",
    "\n",
    "```python\n",
    "from geopy import OpenMapQuest\n",
    "```\n",
    "\n",
    "```python\n",
    "def get_geocodes(tweet_list):\n",
    "    \"\"\"Get the latitude and longitude for each tweet's location.\n",
    "    Returns the number of tweets with invalid location data.\"\"\"\n",
    "    print('Getting coordinates for tweet locations...')\n",
    "    geo = OpenMapQuest(api_key=keys.mapquest_key)  # geocoder\n",
    "    bad_locations = 0  \n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        processed = False\n",
    "        delay = .1  # used if OpenMapQuest times out to delay next call\n",
    "        while not processed:\n",
    "            try:  # get coordinates for tweet['location']\n",
    "                geo_location = geo.geocode(tweet['location'])\n",
    "                processed = True\n",
    "            except:  # timed out, so wait before trying again\n",
    "                print('OpenMapQuest service timed out. Waiting.')\n",
    "                time.sleep(delay)\n",
    "                delay += .1\n",
    "\n",
    "        if geo_location:  \n",
    "            tweet['latitude'] = geo_location.latitude\n",
    "            tweet['longitude'] = geo_location.longitude\n",
    "        else:  \n",
    "            bad_locations += 1  # tweet['location'] was invalid\n",
    "    \n",
    "    print('Done geocoding')\n",
    "    return bad_locations\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function (cont.)\n",
    "* Creates the **`OpenMapQuest` object** we’ll use to geocode locations\n",
    "* Initializes **`bad_locations`** which we use to keep track of the number of invalid locations in the tweet objects we collected\n",
    "* Attempts to **geocode the current tweet’s location**\n",
    "* Prints a message that it’s done geocoding and returns the `bad_locations` value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.3 Class `LocationListener`\n",
    "```python\n",
    "# locationlistener.py\n",
    "\"\"\"Receives tweets matching a search string and stores a list of\n",
    "dictionaries containing each tweet's screen_name/text/location.\"\"\"\n",
    "import tweepy\n",
    "from tweetutilities import get_tweet_content\n",
    "\n",
    "class LocationListener(tweepy.StreamListener):\n",
    "    \"\"\"Handles incoming Tweet stream to get location data.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def __init__(self, api, counts_dict, tweets_list, topic, limit=10):\n",
    "        \"\"\"Configure the LocationListener.\"\"\"\n",
    "        self.tweets_list = tweets_list\n",
    "        self.counts_dict = counts_dict\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "        super().__init__(api)  # call superclass's init\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def on_status(self, status):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "        # get each tweet's screen_name, text and location\n",
    "        tweet_data = get_tweet_content(status, location=True)  \n",
    "\n",
    "        # ignore retweets and tweets that do not contain the topic\n",
    "        if (tweet_data['text'].startswith('RT') or\n",
    "            self.topic.lower() not in tweet_data['text'].lower()):\n",
    "            return\n",
    "\n",
    "        self.counts_dict['total_tweets'] += 1  # original tweet\n",
    "\n",
    "        # ignore tweets with no location \n",
    "        if not status.user.location:  \n",
    "            return\n",
    "\n",
    "        self.counts_dict['locations'] += 1  # tweet with location\n",
    "        self.tweets_list.append(tweet_data)  # store the tweet\n",
    "        print(f'{status.user.screen_name}: {tweet_data[\"text\"]}\\n')\n",
    "        \n",
    "        # if TWEET_LIMIT is reached, return False to terminate streaming\n",
    "        return self.counts_dict['locations'] != self.TWEET_LIMIT\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.3 Class `LocationListener` (cont.)\n",
    "* Method `on_status`:\n",
    "    * Calls `get_tweet_content` to get the screen name, text and location of each tweet.\n",
    "    * Ignores the tweet if it is a retweet or if the text does not include the topic we’re searching for—we’ll use only original tweets containing the search string.\n",
    "    * Adds 1 to the value of the `'total_tweets'` key in the `counts` dictionary to track the number of original tweets we process.\n",
    "    * Ignores tweets that have no location data.\n",
    "    * Adds 1 to the value of the `'locations'` key in the `counts` dictionary to indicate that we found a tweet with a location.\n",
    "    * Appends to the `tweets_list` the `tweet_data` dictionary that `get_tweet_content` returned.\n",
    "    * Displays the tweet’s screen name and tweet text \n",
    "    * Checks whether the `TWEET_LIMIT` has been reached and, if so, returns `False` to terminate the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
