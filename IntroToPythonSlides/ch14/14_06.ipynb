{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.6 Case Study: Traveler’s Companion Translation App\n",
    "* Use three **IBM Watson services** to quickly **implement** a **traveler’s companion translation app**\n",
    "    * Enables people who **speak only English** and **speak only Spanish to **converse**\n",
    "* Combining services like this is known as creating a **mashup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6.1 Before You Run the App \n",
    "* You’ll use **Lite (free) tiers** \n",
    "* Requires an **IBM Cloud account** and **credentials** for each service\n",
    "* **Once you have your credentials** (described below), **insert them in our `keys.py` file** (located in the `ch14` examples folder) that we import into the example.\n",
    "* Never share your credentials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering for the Speech to Text Service \n",
    "* App uses **Watson Speech to Text service** to transcribe English and Spanish audio files to English and Spanish text, respectively. \n",
    "* To get credentials:\n",
    "\t1. **Create a Service Instance:** Go to https://console.bluemix.net/catalog/services/speech-to-text and click the **Create** button on the bottom of the page. This auto-generates an API key for you and takes you to a tutorial for working with the Speech to Text service.\n",
    "\t2. **Get Your Service Credentials:** To see your API key, click **Manage** at the top-left of the page. To the right of **Credentials**, click **Show credentials**, then copy the **API Key**, and paste it into the variable `speech_to_text_key`’s string in the `keys.py` file provided in this chapter’s `ch14` examples folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering for the Text to Speech Service\n",
    "* In this app, you’ll use the **Watson Text to Speech service** to synthesize speech from text. \n",
    "* Toget credentials:\n",
    "\t1. **Create a Service Instance:** Go to https://console.bluemix.net/catalog/services/text-to-speech and click the **Create** button on the bottom of the page. This auto-generates an API key for you and takes you to a tutorial for working with the Text to Speech service.\n",
    "\t2. **Get Your Service Credentials:** To see your API key, click **Manage** at the top-left of the page. To the right of **Credentials**, click **Show credentials**, then copy the **API Key** and paste it into the variable `text_to_speech_key`’s string in the `keys.py` file provided in this chapter’s `ch14` examples folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering for the Language Translator Service\n",
    "* In this app, you’ll use the **Watson Language Translator service** to pass text to Watson and receive back the text translated into another language. \n",
    "* To get credentials:\n",
    "\t1. **Create a Service Instance:** Go to https://console.bluemix.net/catalog/services/language-translator and click the **Create** button on the bottom of the page. This **auto-generates an API key** for you and takes you to a page to manage your instance of the service.\n",
    "\t2. **Get Your Service Credentials:** To the right of **Credentials**, click **Show credentials**, then copy the **API Key** and paste it into the variable `translate_key`’s string in the `keys.py` file provided in this chapter’s chch1413 examples folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Your Credentials \n",
    "* To view your credentials at any time, click the appropriate service instance at: \n",
    ">https://console.bluemix.net/dashboard/apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6.2 Test-Driving the App\n",
    "* Once you’ve added your credentials to the script, run it by executing the following command from the `ch14` examples folder:\n",
    "```python\n",
    "ipython SimpleLanguageTranslator.py\n",
    "```\n",
    "    * **NOTE:** The `pydub.playback` module we use in this app may issue a warning having to do with features we don’t use. This can be ignored. To eliminate it, install `ffmpeg` for Windows, macOS or Linux from https://www.ffmpeg.org. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Question\n",
    "* The app performs **10 steps**, which we point out via comments in the code. \n",
    "* **Step 1** prompts for and records a question. \n",
    "    * First, the app displays the following text and waits for you to press _Enter_\n",
    "    >`Press Enter then ask your question in English`\n",
    "    * When you do, the app displays:\n",
    "    >`Recording 5 seconds of audio`\n",
    "    * Speak your question: We said, “Where is the closest bathroom?” \n",
    "    * After five seconds, the app displays:\n",
    "    >`Recording complete`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Question (cont.)\n",
    "* **Step 2** interacts with **Watson’s Speech to Text service** to **transcribe your audio to text and displays the result:\n",
    ">`English: where is the closest bathroom` \n",
    "* **Step 3** then uses **Watson’s Language Translator service** to **translate the English text to Spanish** and displays the translated text returned by Watson:\n",
    ">`Spanish: ¿Dónde está el baño más cercano?` \n",
    "* **Step 4** passes this Spanish text to **Watson’s Text to Speech service** to **convert the text to an audio file**. \n",
    "* **Step 5** plays the resulting Spanish audio file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Response\n",
    "* At this point, we’re ready to **process the Spanish speaker’s response**. \n",
    "* **Step 6** displays the following text and waits for you to press _Enter_\n",
    ">`Press Enter then speak the Spanish answer`\n",
    "* When you do, the app displays the following text and the  **Spanish speaker records a response.**:\n",
    ">`Recording 5 seconds of audio`\n",
    "    * **We do not speak Spanish, so we used Watson’s Text to Speech service to _prerecord_ Watson saying the Spanish response “El baño más cercano está en el restaurante,” then played that audio loud enough for our computer’s microphone to record it.**\n",
    "    * Provided this **prerecorded audio** for you as `SpokenResponse.wav` in the `ch14` folder. \n",
    "    * If you use this file, play it quickly after pressing _Enter_ above as the app records for only 5 seconds\n",
    "    * To ensure that the audio loads and plays quickly, you might want to play it once before you press _Enter_ to begin recording. \n",
    "    * For simplicity, we set the app to record five seconds of audio. You can control the duration with the variable SECONDS in function `record_audio`. It’s possible to create a recorder that begins recording once it detects sound and stops recording after a period of silence, but the code is more complicated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Response (cont.)\n",
    "* After five seconds, the app displays:\n",
    ">`Recording complete`\n",
    "* **Step 7** interacts with **Watson’s Speech to Text service** to **transcribe the Spanish audio to text** and displays the result:\n",
    ">`Spanish response: el baño más cercano está en el restaurante` \n",
    "* **Step 8** then uses **Watson’s Language Translator service** to **translate the Spanish text to English** and displays the result:\n",
    ">`English response: The nearest bathroom is in the restaurant` \n",
    "* **Step 9** passes the English text to **Watson’s Text to Speech service** to **convert the text to an audio file**. \n",
    "* **Step 10** then plays the resulting English audio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.6.3 `SimpleLanguageTranslator.py` Script Walkthrough\n",
    "* The script is divided into **10 steps**, each marked with comments in the code\n",
    "* **Processing the English question** \n",
    "> **Step 1:** Prompt for then **record English speech** into an audio file  \n",
    "**Step 2:** **Transcribe** the English speech to **English text**  \n",
    "**Step 3:** **Translate** the English text into Spanish text  \n",
    "**Step 4:** **Synthesize** the Spanish text into **Spanish speech** and save it into an audio file  \n",
    "**Step 5:** **Play** the Spanish **audio** file  \n",
    "* **Processing the Spanish response**  \n",
    "> **Step 6:** Prompt for then **record Spanish speech** into an audio file  \n",
    "    **Step 7:** **Transcribe** the Spanish speech to **Spanish text**  \n",
    "    **Step 8:** **Translate** the Spanish text into English text  \n",
    "    **Step 9:** **Synthesize** the English text into **English speech** and save it into an audio file  \n",
    "    **Step 10:** **Play** the English **audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Watson SDK Classes  \n",
    "* **`SpeechToTextV1`** \n",
    "    * Passes an **audio file** to the **Watson Speech to Text service** \n",
    "    * Receives a **JSON document** containing the **text transcription**\n",
    "* **`LanguageTranslatorV3`** \n",
    "    * Passes **text** to the **Watson Language Translator service** \n",
    "    * Receives a **JSON document** containing the **translated text** \n",
    "* **`TextToSpeechV1`** \n",
    "    * Passes **text** to the **Watson Text to Speech service** \n",
    "    * Receives **audio** of the text **spoken in a specified language**\n",
    "\n",
    "\n",
    "```python\n",
    "# SimpleLanguageTranslator.py\n",
    "\"\"\"Use IBM Watson Speech to Text, Language Translator and Text to Speech\n",
    "   APIs to enable English and Spanish speakers to communicate.\"\"\"\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson import LanguageTranslatorV3\n",
    "from ibm_watson import TextToSpeechV1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Imported Modules\n",
    "* **`pyaudio`** for **recording audio** \n",
    "* **`pydub`** and **`pydub.playback`** to **load and play audio files**\n",
    "* **`wave`** to save **WAV (Waveform Audio File Format) files**\n",
    "\n",
    "```python\n",
    "import keys  # contains your API keys for accessing Watson services\n",
    "import pyaudio  # used to record from mic\n",
    "import pydub  # used to load a WAV file\n",
    "import pydub.playback  # used to play a WAV file\n",
    "import wave  # used to save a WAV file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (1 of 6)\n",
    "* **`run_translator`** invoked when **`SimpleLanguageTranslator.py` executed as a script**\n",
    "\n",
    "```python\n",
    "def run_translator():\n",
    "    \"\"\"Calls the functions that interact with Watson services.\"\"\"\n",
    "    # Step 1: Prompt for then record English speech into an audio file \n",
    "    input('Press Enter then ask your question in English')\n",
    "    record_audio('english.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (2 of 6)\n",
    "* **Step 2**: Call **`speech_to_text`**\n",
    "    * **Speech to Text service** transcribes text using **predefined models**\n",
    "        * Most languages have **broadband** (**>=16kHZ**) and **narrowband** (**<16kHZ**) models (based on **audio quality**)\n",
    "        * App **captures** audio at **44.1 kHZ**, so we use **`'en-US_BroadbandModel'`**\n",
    "\n",
    "```python\n",
    "    # Step 2: Transcribe the English speech to English text\n",
    "    english = speech_to_text(\n",
    "        file_name='english.wav', model_id='en-US_BroadbandModel')\n",
    "    print('English:', english)  # display transcription\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (3 of 6)\n",
    "* **Step 3**: Call **`translate`**\n",
    "    * **Predefined model `'en-es'`** translates from **English (`en`) to Spanish (`es`)**\n",
    "\n",
    "```python\n",
    "    # Step 3: Translate the English text into Spanish text\n",
    "    spanish = translate(text_to_translate=english, model='en-es')\n",
    "    print('Spanish:', spanish)  # display translated text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (4 of 6)\n",
    "* **Voice `'es-US_SofiaVoice'`** is for Spanish as spoken in the U.S.\n",
    "\n",
    "```python    \n",
    "    # Step 4: Synthesize the Spanish text into Spanish speech \n",
    "    text_to_speech(text_to_speak=spanish, voice_to_use='es-US_SofiaVoice',\n",
    "        file_name='spanish.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (5 of 6)\n",
    "* **Step 5**: Call **`play_audio`** to play the file **`'spanish.wav'`**.\n",
    "\n",
    "```python\n",
    "    # Step 5: Play the Spanish audio file\n",
    "    play_audio(file_name='spanish.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (6 of 6)\n",
    "* **Steps 6–10** repeat previous steps for **Spanish speech to English speech**: \n",
    "    * **Step 6** **records** the Spanish audio\n",
    "    * **Step 7** **transcribes** the **Spanish audio** to Spanish text using predefined model **`'es-ES_BroadbandModel'`**\n",
    "    * **Step 8** **translates** the **Spanish text** to English text using predefined model **`'es-en'`** (Spanish-to-English)\n",
    "    * **Step 9** **creates** the **English audio** using **`'en-US_AllisonVoice'`**\n",
    "    * **Step 10** **plays** the English **audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # Step 6: Prompt for then record Spanish speech into an audio file\n",
    "    input('Press Enter then speak the Spanish answer')\n",
    "    record_audio('spanishresponse.wav')\n",
    "\n",
    "    # Step 7: Transcribe the Spanish speech to Spanish text\n",
    "    spanish = speech_to_text(\n",
    "        file_name='spanishresponse.wav', model_id='es-ES_BroadbandModel')\n",
    "    print('Spanish response:', spanish)\n",
    "\n",
    "    # Step 8: Translate the Spanish text to English text\n",
    "    english = translate(text_to_translate=spanish, model='es-en')\n",
    "    print('English response:', english)\n",
    "\n",
    "    # Step 9: Synthesize the English text to English speech\n",
    "    text_to_speech(text_to_speak=english,\n",
    "        voice_to_use='en-US_AllisonVoice',\n",
    "        file_name='englishresponse.wav')\n",
    "\n",
    "    # Step 10: Play the English audio\n",
    "    play_audio(file_name='englishresponse.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (1 of 4) Accesses **Watson’s Speech to Text Service**\n",
    "```python\n",
    "def speech_to_text(file_name, model_id):\n",
    "    \"\"\"Use Watson Speech to Text to convert audio file to text.\"\"\"\n",
    "    # create Watson Speech to Text client \n",
    "    stt = SpeechToTextV1(iam_apikey=keys.speech_to_text_key)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (2 of 4) Accesses **Watson’s Speech to Text Service**\n",
    "```python\n",
    "    # open the audio file \n",
    "    with open(file_name, 'rb') as audio_file:\n",
    "        # pass the file to Watson for transcription\n",
    "        result = stt.recognize(audio=audio_file, \n",
    "            content_type='audio/wav', model=model_id).get_result()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (3 of 4)\n",
    "* **`recognize`** returns a **`DetailedResponse` object** \n",
    "    * Depending on arguments to **`recognize`**, may contain intermediate and final results\n",
    "    * Useful when transcribing **live audio**, such as a newscast\n",
    "    * [Method `recognize`’s arguments and JSON response details](https://www.ibm.com/watson/developercloud/speech-to-text/api/v1/python.html?python#recognize-sessionless).\n",
    "* **`getResult` method** returns **JSON** containing **`transcript`**:\n",
    "    ![JSON returned from SpeechToTextV1 recognize method](./ch14images/RecognizeDetailedResponse.png \"JSON returned from SpeechToTextV1 recognize method\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (4 of 4) Accesses **Watson’s Speech to Text Service**\n",
    "```python\n",
    "    # Get the 'results' list. This may contain intermediate and final\n",
    "    # results, depending on method recognize's arguments. We asked \n",
    "    # for only final results, so this list contains one element.\n",
    "    results_list = result['results'] \n",
    "\n",
    "    # Get the final speech recognition result--the list's only element.\n",
    "    speech_recognition_result  = results_list[0]\n",
    "\n",
    "    # Get the 'alternatives' list. This may contain multiple alternative\n",
    "    # transcriptions, depending on method recognize's arguments. We did\n",
    "    # not ask for alternatives, so this list contains one element.\n",
    "    alternatives_list = speech_recognition_result['alternatives']\n",
    "\n",
    "    # Get the only alternative transcription from alternatives_list.\n",
    "    first_alternative = alternatives_list[0]\n",
    "\n",
    "    # Get the 'transcript' key's value, which contains the audio's \n",
    "    # text transcription.\n",
    "    transcript = first_alternative['transcript']\n",
    "\n",
    "    return transcript  # return the audio's text transcription\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` (1 of 4) Accesses the **Watson Language Translator Service**\n",
    "* Creates a **`LanguageTranslatorV3`**, passing **service version (`'2018-05-01'`)** and **API Key**\n",
    "    * **Version string (`'2018-05-01'`)** changes only if IBM makes **breaking API changes** \n",
    "    * Service still responds using **API version you specify**\n",
    "    * [More details](https://cloud.ibm.com/apidocs/language-translator?code=python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` (2 of 4)\n",
    "```python\n",
    "def translate(text_to_translate, model):\n",
    "    \"\"\"Use Watson Language Translator to translate English to Spanish \n",
    "       (en-es) or Spanish to English (es-en) as specified by model.\"\"\"\n",
    "    # create Watson Translator client\n",
    "    language_translator = LanguageTranslatorV3(version='2018-05-01',\n",
    "        iam_apikey=keys.translate_key)\n",
    "\n",
    "    # perform the translation\n",
    "    translated_text = language_translator.translate(\n",
    "        text=text_to_translate, model_id=model).get_result()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` Returns a **`DetailedResponse`** (4 of 4)\n",
    "* **`getResult` method** returns **JSON** containing **translation**:  \n",
    "    ![JSON returned from LanguageTranslatorV3 translate method](./ch14images/TranslateDetailedResponse.png \"JSON returned from LanguageTranslatorV3 translate method\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` (3 of 4)\n",
    "```python\n",
    "    # get 'translations' list. If method translate's text argument has \n",
    "    # multiple strings, the list will have multiple entries. We passed\n",
    "    # one string, so the list contains only one element.\n",
    "    translations_list = translated_text['translations']\n",
    "    \n",
    "    # get translations_list's only element\n",
    "    first_translation = translations_list[0]\n",
    "\n",
    "    # get 'translation' key's value, which is the translated text\n",
    "    translation = first_translation['translation']\n",
    "\n",
    "    return translation  # return the translated string\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `text_to_speech` Accesses **Watson Text to Speech Service** (1 of 2)\n",
    "* Creates a **`TextToSpeechV1` object** named `tts` (short for text-to-speech), passing the **API key**. \n",
    "* **`with` statement** opens audio file for writing.  \n",
    "\n",
    "```python\n",
    "def text_to_speech(text_to_speak, voice_to_use, file_name):\n",
    "    \"\"\"Use Watson Text to Speech to convert text to specified voice\n",
    "       and save to a WAV file.\"\"\"\n",
    "    # create Text to Speech client\n",
    "    tts = TextToSpeechV1(iam_apikey=keys.text_to_speech_key)\n",
    "\n",
    "    # open file and write the synthesized audio content into the file\n",
    "    with open(file_name, 'wb') as audio_file:\n",
    "        audio_file.write(tts.synthesize(text_to_speak, \n",
    "            accept='audio/wav', voice=voice_to_use).get_result().content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `text_to_speech` (3 of 3)\n",
    "* **`synthesize`** method's **`voice`** argument is a **predefined voice** \n",
    "    * **`'en-US_AllisonVoice'`** or **`'es-US_SofiaVoice'`** in this example\n",
    "    *  [**Voices for various languages**](https://cloud.ibm.com/apidocs/text-to-speech?code=python)\n",
    "* **`get_result`** returns a **`DetailedResponse`** containing **spoken audio as bytes**\n",
    "    * **`content` attribute** gets the **audio bytes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions `record_audio` and `play_audio`\n",
    "* **Instructor Note:** We recommend having students use these two functions as is, rather than presenting them in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `record_audio` (2 of 4)\n",
    "```python \n",
    "def record_audio(file_name):\n",
    "    \"\"\"Use pyaudio to record 5 seconds of audio to a WAV file.\"\"\"\n",
    "    FRAME_RATE = 44100  # number of frames per second\n",
    "    CHUNK = 1024  # number of frames read at a time\n",
    "    FORMAT = pyaudio.paInt16  # each frame is a 16-bit (2-byte) integer\n",
    "    CHANNELS = 2  # 2 samples per frame\n",
    "    SECONDS = 5  # total recording time\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "    recorder = pyaudio.PyAudio()  # opens/closes audio streams\n",
    "\n",
    "    # configure and open audio stream for recording (input=True)\n",
    "    audio_stream = recorder.open(format=FORMAT, channels=CHANNELS, \n",
    "        rate=FRAME_RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    audio_frames = []  # stores raw bytes of mic input\n",
    "    print('Recording 5 seconds of audio')\n",
    "\n",
    "    # read 5 seconds of audio in CHUNK-sized pieces\n",
    "    for i in range(0, int(FRAME_RATE * SECONDS / CHUNK)):\n",
    "        audio_frames.append(audio_stream.read(CHUNK))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "    print('Recording complete')\n",
    "    audio_stream.stop_stream()  # stop recording\n",
    "    audio_stream.close()  \n",
    "    recorder.terminate()  # release underlying resources used by PyAudio\n",
    "\n",
    "    # save audio_frames to a WAV file\n",
    "    with wave.open(file_name, 'wb') as output_file:\n",
    "        output_file.setnchannels(CHANNELS)\n",
    "        output_file.setsampwidth(recorder.get_sample_size(FORMAT))\n",
    "        output_file.setframerate(FRAME_RATE)\n",
    "        output_file.writeframes(b''.join(audio_frames))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `play_audio` Using Features of **`pydub`** and **`pydub.playback`** Modules \n",
    "```python\n",
    "def play_audio(file_name):\n",
    "    \"\"\"Use the pydub module (pip install pydub) to play a WAV file.\"\"\"\n",
    "    sound = pydub.AudioSegment.from_wav(file_name)  # load audio\n",
    "    pydub.playback.play(sound)  # play audio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the `run_translator` Function\n",
    "* **`run_translator`** called only when **`SimpleLanguageTranslator.py`** executes as a script:\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    run_translator()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
